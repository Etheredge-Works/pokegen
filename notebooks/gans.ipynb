{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import sprites\n",
    "latent_dim = 256\n",
    "trainloader, valloader = sprites.get_loader(\n",
    "        batch_size=64,\n",
    "        workers=16,\n",
    "        val_ratio=0.0, \n",
    "        path=\"../data/external/sprites\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(trainloader))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, label in iter(trainloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.gans import GAN, DCGAN\n",
    "from autoencoder.encoders import ConvEncoder\n",
    "from autoencoder.decoders import ConvDecoder\n",
    "from pl_bolts.datamodules import MNISTDataModule, CIFAR10DataModule\n",
    "import torchmetrics\n",
    "\n",
    "import torch \n",
    "from torch import Tensor\n",
    "\n",
    "class CustomDCGAN(DCGAN):\n",
    "    def __init__(self, swap_prob=0.3, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.real_accuracy = torchmetrics.Accuracy()\n",
    "        self.fake_accuracy = torchmetrics.Accuracy()\n",
    "        self.swap_prob = swap_prob\n",
    "\n",
    "    def _get_disc_loss(self, real: Tensor) -> Tensor:\n",
    "        # Train with real\n",
    "        # print(f\"real shape: {real.shape}\")\n",
    "        real_pred = self.discriminator(real)\n",
    "        # print(f\"real_pred shape: {real_pred.shape}\")\n",
    "        # real_gt = torch.ones_like(real_pred)\n",
    "\n",
    "        # real_acc = self.real_accuracy(real_pred.cpu(), torch.ones_like(real_pred).type(torch.long).cpu())\n",
    "        real_acc = self.real_accuracy(real_pred, torch.ones_like(real_pred, device=real_pred.device).type(torch.long))\n",
    "        self.log(\"acc/real\", real_acc, on_epoch=True, on_step=False)\n",
    "\n",
    "        # Train with fake\n",
    "        fake_pred = self._get_fake_pred(real)\n",
    "        # fake_gt = torch.zeros_like(fake_pred)\n",
    "        fake_acc = self.fake_accuracy(fake_pred, torch.zeros_like(fake_pred, device=fake_pred.device).type(torch.long))\n",
    "        # fake_acc = self.fake_accuracy(fake_pred.cpu(), torch.zeros_like(fake_pred).type(torch.long).cpu())\n",
    "        self.log(\"acc/fake\", fake_acc, on_epoch=True, on_step=False)\n",
    "\n",
    "        # Soften labels\n",
    "        real_gt = (0.7 - 1.2) * torch.rand_like(real_pred) + 1.2\n",
    "        fake_gt = (0.0 - 0.3) * torch.rand_like(fake_pred) + 0.3\n",
    "\n",
    "        # Randomly swap labels\n",
    "        swap_chances = torch.rand_like(real_pred)\n",
    "        # print(swap_chances.shape)\n",
    "        real_gt = torch.where(swap_chances < self.swap_prob, fake_gt, real_gt)\n",
    "        fake_gt = torch.where(swap_chances < self.swap_prob, real_gt, fake_gt)\n",
    "\n",
    "        # Loss\n",
    "        real_loss = self.criterion(real_pred, real_gt)\n",
    "        fake_loss = self.criterion(fake_pred, fake_gt)\n",
    "\n",
    "        disc_loss = real_loss + fake_loss\n",
    "\n",
    "        dis_acc = (real_acc + fake_acc) / 2 # MAYBE BAD?\n",
    "        self.log(\"acc/total\", dis_acc, on_epoch=True, on_step=False)\n",
    "\n",
    "        return disc_loss\n",
    "\n",
    "class BenGAN(DCGAN):\n",
    "    def init_generator(self, img_dim):\n",
    "        generator = ConvDecoder(\n",
    "            latent_shape=self.hparams.latent_dim, \n",
    "            output_shape=img_dim,\n",
    "            final_activation=torch.tanh,)\n",
    "        return generator\n",
    "    \n",
    "    def init_discriminator(self, img_dim):\n",
    "        discriminator = ConvEncoder(\n",
    "            input_shape=img_dim,\n",
    "            latent_shape=1,\n",
    "            final_activation=torch.sigmoid,\n",
    "            dropout_rate=0.1)\n",
    "        return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.gans import GAN, DCGAN, SRResNet, SRGAN\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pl_bolts.callbacks import LatentDimInterpolator, TensorboardGenerativeModelImageSampler\n",
    "import torchvision\n",
    "\n",
    "logger = WandbLogger(project=\"gan_test\")\n",
    "# gan = BenGAN(3, 96, 96, latent_dim=latent_dim)\n",
    "# gan = DCGAN(image_channels=3, feature_maps_disc=16, feature_maps_gen=16, latent_dim=latent_dim)\n",
    "# gan = CustomDCGAN(image_channels=3, feature_maps_disc=32, feature_maps_gen=128, latent_dim=latent_dim)\n",
    "gan = CustomDCGAN(image_channels=3, latent_dim=64)\n",
    "# gan = DCGAN(image_channels=3)\n",
    "# gan = SRResNet()\n",
    "# gan = SRGAN(scale_factor=2)\n",
    "# gan = SRResNet(image_channels=3, feature_maps=16, latent_dim=latent_dim)\n",
    "print(gan)\n",
    "# gan = GAN(3, 96, 96, latent_dim=latent_dim)\n",
    "#gan = GAN(1, 28, 28, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=-1, \n",
    "    logger=logger, \n",
    "    # logger=pl.\n",
    "    callbacks=[\n",
    "        TensorboardGenerativeModelImageSampler(num_samples=64, nrow=8, normalize=True, ),\n",
    "        LatentDimInterpolator(interpolate_epoch_interval=4)],\n",
    "    strategy=\"dp\",\n",
    "    max_epochs=500, \n",
    "    log_every_n_steps=10,\n",
    "    track_grad_norm=2)\n",
    "\n",
    "# trainloadersssss = CIFAR10DataModule(\n",
    "#     \"/tmp/\", \n",
    "#     num_workers=16,\n",
    "#     drop_last=True,\n",
    "#     train_transforms=torchvision.transforms.Compose([\n",
    "#         torchvision.transforms.RandomHorizontalFlip(),\n",
    "#         torchvision.transforms.Resize((64, 64)),\n",
    "#         torchvision.transforms.ToTensor(),\n",
    "#         torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "#     ]),\n",
    "#     pin_memory=True,\n",
    "#     batch_size=256)\n",
    "#trainer.fit(gan, train_dataloaders=MNISTDataModule(num_workers=0, batch_size=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(gan, train_dataloaders=trainloader) #, val_dataloaders=valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "noise = torch.rand(32, latent_dim).to(device=gan.device)\n",
    "img = gan(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img.detach().cpu().numpy()[0] \n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.swapaxes(0,1)\n",
    "image = image.swapaxes(1,2)\n",
    "#image = image.swapaxes(0,2)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "noise = torch.rand(16, latent_dim).to(device=gan.device)\n",
    "img = gan(noise)\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "images = img.detach().cpu().numpy()\n",
    "for image in images:\n",
    "    image = np.squeeze(image)\n",
    "    print(image.shape)\n",
    "    image = image.swapaxes(0,1)\n",
    "    image = image.swapaxes(1,2)\n",
    "    PIL_image = Image.fromarray((image*255).astype('uint8'),'RGB')\n",
    "    #PIL_image = Image.fromarray((image).astype('uint8'),'F')\n",
    "    #PIL_image = Image.fromarray((image*255),'F')\n",
    "    PIL_image.show()\n",
    "\n",
    "# PIL_image = Image.fromarray(img[0]).astype('uint8'), 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
