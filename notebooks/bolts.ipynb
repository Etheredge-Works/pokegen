{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pl_bolts.models.autoencoders import AE, VAE\n",
    "from basic_ae_module import AE\n",
    "from basic_vae_module import VAE\n",
    "EPOCHS = 2000\n",
    "IM_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "ROWS = 8\n",
    "# ae = AE(input_height=96, enc_type=\"resnet50\", enc_out_dim=2048, latent_dim=256) #, kl_coeff=1.0)\n",
    "ae = VAE(\n",
    "    input_height=IM_SIZE, \n",
    "    enc_type=\"resnet18\", \n",
    "    enc_out_dim=512, \n",
    "    # enc_type=\"custom\", \n",
    "    # enc_out_dim=512, \n",
    "    latent_dim=512,\n",
    "    kl_coeff=0.1,\n",
    "    # kl_warmup=EPOCHS//5,\n",
    "    lr=1e-6) #, kl_coeff=1.0)\n",
    "# print(VAE.pretrained_weights_available())\n",
    "# ae = ae.from_pretrained('cifar10-resnet18')\n",
    "\n",
    "# ae.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.datasets import CIFAR10, CIFAR100, MNIST, CelebA\n",
    "# ds = CelebA(root='/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import sprites\n",
    "from torchvision.datasets import CelebA, LFWPairs, MNIST\n",
    "import torchvision\n",
    "import torch\n",
    "train, val  = sprites.get_loader(\n",
    "    batch_size=BATCH_SIZE, \n",
    "    workers=16, \n",
    "    val_ratio=0.1,\n",
    "    resize_shape=(IM_SIZE, IM_SIZE))\n",
    "# data = CelebA(\n",
    "#         root=\"./data\", \n",
    "#         # root=\"/data/torch/\", \n",
    "#         download=False, \n",
    "#         transform=torchvision.transforms.Compose([\n",
    "#             torchvision.transforms.Resize((64, 64)),\n",
    "#             torchvision.transforms.RandomHorizontalFlip(),\n",
    "#             torchvision.transforms.ToTensor(),\n",
    "#             torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "#         ]))\n",
    "# data = MNIST(\n",
    "#         root=\"./data\", \n",
    "#         # root=\"/data/torch/\", \n",
    "#         download=True, \n",
    "#         transform=torchvision.transforms.Compose([\n",
    "#             torchvision.transforms.Resize((64, 64)),\n",
    "#             # torchvision.transforms.RandomHorizontalFlip(),\n",
    "#             torchvision.transforms.ToTensor(),\n",
    "#             # torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "#             torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
    "#         ]))\n",
    "# val_count = int(len(data) * 0.1)\n",
    "# train, val = torch.utils.data.random_split(data, [len(data)-val_count, val_count])\n",
    "# train = torch.utils.data.DataLoader(\n",
    "#     train, \n",
    "#     batch_size=BATCH_SIZE, \n",
    "#     pin_memory=True,\n",
    "#     persistent_workers=True,\n",
    "#     shuffle=True, \n",
    "#     num_workers=24)\n",
    "# val = torch.utils.data.DataLoader(\n",
    "#     val, \n",
    "#     batch_size=BATCH_SIZE, \n",
    "#     pin_memory=True,\n",
    "#     persistent_workers=True,\n",
    "#     shuffle=False, \n",
    "#     num_workers=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item, label = (next(iter(train)))\n",
    "import numpy as np\n",
    "print(np.max(item.numpy()))\n",
    "print(np.min(item.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item, label = (next(iter(train)))\n",
    "item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.callbacks import BasePredictionWriter, StochasticWeightAveraging, Callback, EarlyStopping\n",
    "import os\n",
    "import os\n",
    "from typing import Any, List\n",
    "import utils\n",
    "import torchvision\n",
    "\n",
    "class CustomWriter(Callback):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Any,\n",
    "        write_interval: int = 20,\n",
    "        num_rows: int = 1,\n",
    "        normalize: bool = False,\n",
    "        post_fix: str = \"\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.write_interval = write_interval\n",
    "        self.data = data\n",
    "        self.num_rows = num_rows\n",
    "        self.normalize = normalize\n",
    "        self.post_fix = post_fix\n",
    "\n",
    "    def on_epoch_end(self, trainer: \"pl.Trainer\", ae_module: \"pl.LightningModule\") -> None:\n",
    "\n",
    "        # print(\"writing batch\")\n",
    "        # torch.save(prediction, os.path.join(\n",
    "        #     self.output_dir, dataloader_idx, f\"{batch_idx}.pt\"))\n",
    "\n",
    "        if (trainer.current_epoch + 1) % self.write_interval == 0:\n",
    "            ae_module.eval()\n",
    "            with torch.no_grad():\n",
    "                results = ae_module.encode_decode(self.data.to(ae_module.device))\n",
    "\n",
    "\n",
    "            grid_og = torchvision.utils.make_grid(self.data, nrow=self.num_rows, normalize=self.normalize)\n",
    "            grid = torchvision.utils.make_grid(results, nrow=self.num_rows, normalize=self.normalize)\n",
    "            str_title = f\"{ae_module.__class__.__name__}_encode_decode{self.post_fix}\"\n",
    "            str_title_og = f\"{ae_module.__class__.__name__}_og{self.post_fix}\"\n",
    "            # trainer.logger.experiment.add_image(str_title, grid, global_step=trainer.global_step)\n",
    "            trainer.logger.log_image(key=str_title, images=[grid], step=trainer.global_step)\n",
    "            trainer.logger.log_image(key=str_title_og, images=[grid_og], step=trainer.global_step)\n",
    "        # utils.save_image(\n",
    "        #     results, \n",
    "        #     os.path.join(self.output_dir, \"preds\"), \n",
    "        #     # convert_func=sprites.denormalize\n",
    "        #     )\n",
    "    # def write_on_epoch_end(\n",
    "    #     self, trainer, pl_module: 'LightningModule', predictions: List[Any], batch_indices: List[Any]\n",
    "    # ):\n",
    "# TODO why did switching from mse to binary crossentropy make it use so much less memory???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)\n",
    "# from pl_bolts.callbacks import LatentDimInterpolator, TensorboardGenerativeModelImageSampler\n",
    "from utils import WandbGenerativeModelImageSampler, LatentDimInterpolator\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=f\"{ae.__class__.__name__}_logs/\")\n",
    "wandb_logger = pl_loggers.WandbLogger(\n",
    "    project=\"pokegen-vae\"\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=EPOCHS, \n",
    "    accelerator='auto', \n",
    "    devices=-1, \n",
    "    strategy='dp',\n",
    "    # precision=16,\n",
    "    # logger=tb_logger,\n",
    "    logger=wandb_logger,\n",
    "    # gradient_clip_val=1.0,\n",
    "    # detect_anomaly=True,\n",
    "    callbacks=[\n",
    "        WandbGenerativeModelImageSampler(\n",
    "            interpolate_epoch_interval=4,\n",
    "            num_samples=BATCH_SIZE, nrow=ROWS, normalize=True, ),\n",
    "        LatentDimInterpolator(\n",
    "            interpolate_epoch_interval=4, \n",
    "            # range_start=-10, range_end=10, \n",
    "            ),\n",
    "        CustomWriter(\n",
    "            write_interval=4, \n",
    "            data=next(iter(train))[0], \n",
    "            num_rows=ROWS, \n",
    "            normalize=True,\n",
    "            post_fix=\"_train\",),\n",
    "        CustomWriter(\n",
    "            write_interval=4, \n",
    "            data=next(iter(val))[0], \n",
    "            num_rows=ROWS, \n",
    "            normalize=True,\n",
    "            post_fix=\"_val\",),\n",
    "        LearningRateMonitor(),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=150),\n",
    "        ],\n",
    "        # CustomWriter('preds', 'epoch'),\n",
    "        # CustomWriter('preds', 'epoch'),\n",
    ")\n",
    "# trainer.predict(ae, sprites.PokeModule())\n",
    "# trainer.predict(ae, train)\n",
    "trainer.fit(ae, train_dataloaders=train, val_dataloaders=val)\n",
    "# TODO AE loss function with dicriminator for which is actual vs encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = trainer.predict(ae, dataloaders=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
